"""
This script makes a plot of the rate differences between Actor (self) and
Observer (other) conditions for 1R, 1NR, 2NR, and xNR (1NR + 2NR) trials.

It first identifies neurons with a significant rate difference between Actor
and Observer conditions (via rank-sum test) for each history type.

The plot and subsequent analysis are restricted to these significant neurons.
It compares the actual rate difference of this subset to a null distribution
generated by shuffling trial labels and re-running the same significance
selection to test for significance.
"""

import sys
import os
import warnings

# Assuming these paths are correctly set up in your environment
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.LoadSession import findrootdir
from pyTdr.tdrLoadAccData import tdrLoadAccData
from pyTdr.tdrNormalize import smooth_and_normalize
from utils.plots import beutify
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from scipy import stats
from copy import deepcopy
from tqdm import tqdm


def shuffle_actor_observer(dataT):
    """
    Shuffles the 'actor' labels within each 'history' condition for each unit.
    """
    dataT_shuffled = deepcopy(dataT)
    for unit in dataT_shuffled["unit"]:
        task_vars = unit["task_variable"]
        for history_val_internal in [-1, 0, 1]:
            indices = np.where(task_vars["history"] == history_val_internal)[0]
            if len(indices) == 0:
                continue
            actor_labels = task_vars["actor"][indices]
            np.random.shuffle(actor_labels)
            task_vars["actor"][indices] = actor_labels
    return dataT_shuffled


def find_significant_rate_diff_neurons(dataT, initial_sig_units, alpha=0.05):
    """
    Identifies neurons with significant rate differences between Actor and Observer.

    Performs a Wilcoxon rank-sum test for each neuron for each history condition
    """
    time_vector = dataT["time"]
    time_mask = (time_vector >= 0) & (time_vector <= 0.6)
    unit_idx_map = {
        unit["unit_idx_master"]: i for i, unit in enumerate(dataT["unit"])
    }
    # Initialize for all four conditions: 1R, NR
    significant_subsets = {1: [], 2: []}

    for unit_idx_master in initial_sig_units:
        if unit_idx_master not in unit_idx_map:
            continue

        unit = dataT["unit"][unit_idx_map[unit_idx_master]]

        # Test for 1R and xNR (key=2)
        for history_key in [1, 2]:
            if history_key == 1:  # 1R
                history_mask = unit["task_variable"]["history"] == -1
            else:  # xNR case (history is 1NR or 2NR)
                history_mask = np.isin(
                    unit["task_variable"]["history"], [0, 1]
                )  # Internal values for 1NR, 2NR

            actor_trials = np.where(
                (unit["task_variable"]["actor"] == 1) & history_mask
            )[0]
            observer_trials = np.where(
                (unit["task_variable"]["actor"] == -1) & history_mask
            )[0]

            if len(actor_trials) < 3 or len(observer_trials) < 3:
                continue

            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=RuntimeWarning)
                rates_actor1 = np.mean(
                    unit["response"][:, time_mask][actor_trials, :], axis=0
                )
                rates_observer = np.mean(
                    unit["response"][:, time_mask][observer_trials, :], axis=0
                )

            if len(rates_actor1) > 0 and len(rates_observer) > 0:
                _, p_value = stats.ranksums(rates_actor1, rates_observer)
                if p_value < alpha:
                    significant_subsets[history_key].append(unit_idx_master)
    return significant_subsets


def get_mean_rate_for_condition(dataT, unit_indices, history_keys, actor_val):
    """
    Calculates the mean firing rate for a set of neurons under specific conditions.
    """
    if not unit_indices:
        return np.array([])

    time_vector = dataT["time"]
    time_mask = (time_vector >= 0) & (time_vector <= 0.6)
    unit_idx_map = {
        unit["unit_idx_master"]: i for i, unit in enumerate(dataT["unit"])
    }

    mean_rates_per_unit = []

    for unit_idx_master in unit_indices:
        if unit_idx_master not in unit_idx_map:
            mean_rates_per_unit.append(np.nan)
            continue

        unit = dataT["unit"][unit_idx_map[unit_idx_master]]

        # Get internal history values (-1, 0, 1) from keys (1, 2, 3)
        history_vals_internal = [h - 2 for h in history_keys]

        history_mask = np.isin(
            unit["task_variable"]["history"], history_vals_internal
        )
        trial_indices = np.where(
            (unit["task_variable"]["actor"] == actor_val) & history_mask
        )[0]

        if len(trial_indices) == 0:
            mean_rates_per_unit.append(np.nan)
            continue

        # For a single unit, response is (trials, time). Average over time, then over trials.
        trial_rates = np.mean(
            unit["response"][:, time_mask][trial_indices, :], axis=1
        )
        mean_rates_per_unit.append(np.nanmean(trial_rates))

    return np.array(mean_rates_per_unit)


def plot_real_vs_shuffled_diff(root_dir, df_combined, subject="both"):
    """
    Plots the real rate difference against the null distribution from shuffling.
    """
    fig, ax = plt.subplots(figsize=(2, 2))

    df_shuffled = df_combined[df_combined["type"] == "shuffled"]
    df_real = df_combined[df_combined["type"] == "real"]
    order = ["1R", "NR"]

    if not df_shuffled.empty:
        shuffled_means = (
            df_shuffled.groupby(["history_label", "shuffle_iter"])["rate_diff"]
            .mean()
            .reset_index()
        )
        shuffled_stats = (
            shuffled_means.groupby("history_label")["rate_diff"]
            .agg(
                p05=lambda x: np.percentile(x, 5),
                p95=lambda x: np.percentile(x, 95),
                median=np.median,
            )
            .reindex(order)
        )

        for i, hist_label in enumerate(order):
            if hist_label in shuffled_stats.index:
                stats_row = shuffled_stats.loc[hist_label]
                ax.vlines(
                    i,
                    ymin=stats_row.p05,
                    ymax=stats_row.p95,
                    color="lightgray",
                    alpha=0.8,
                    linewidth=12,
                )
                ax.plot(
                    i,
                    stats_row["median"],
                    marker="_",
                    color="dimgray",
                    markersize=16,
                    markeredgewidth=2,
                )

    if not df_real.empty:
        sns.pointplot(
            x="history_label",
            y="rate_diff",
            data=df_real,
            order=order,
            estimator="mean",
            errorbar=("ci", 95),
            seed=0,
            n_boot=1000,
            color="black",
            ax=ax,
            join=False,
            markers="_",
            scale=2,
            errwidth=2,
            capsize=0.1,
        )

    ax.set_xlabel("Trial History")
    ax.set_ylabel("Absolute Rate Difference\n|Actor - Observer|")
    ax.tick_params(direction="out", length=6, width=2)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.set_ylim(0, 0.5)
    ax.legend(frameon=False)
    beutify(ax)

    fignum = {"L": "S11A", "O": "S11B", "both": "S11"}
    fig.savefig(
        f"{root_dir}/plots_paper/Fig{fignum[subject]}_actor_vs_observer_filtered_shuffled_{subject}.pdf",
        dpi=300,
    )
    plt.close(fig)


def main_actor_observer_diff():
    root_dir = findrootdir()
    N_SHUFFLES = 100
    ALPHA = 0.05
    all_diffs_list = []
    stats_summary = {}
    history_map = {1: "1R", 2: "NR"}

    for subject in ["L", "O"]:
        print(f"\nProcessing subject: {subject}")
        dataT, metadata = tdrLoadAccData(root_dir, subject, "fdbk")
        dataT = smooth_and_normalize(dataT)

        # Use all units from master list
        master_list_path = os.path.join(
            root_dir, "master_list_{}.csv".format(subject)
        )
        master_list = pd.read_csv(master_list_path)
        # Filter to only include units that have entry in master_list
        master_list = master_list[
            ~np.isnan(master_list["choice_reward_[-0.6, 0.0]_selectivity_self"])
        ]
        initial_sig_units = master_list["unit_index"].values
        n_initial_units = len(initial_sig_units)
        stats_summary[subject] = {"initial_n": n_initial_units}

        print("Finding significant neurons in real data...")
        real_sig_subsets = find_significant_rate_diff_neurons(
            dataT, initial_sig_units, alpha=ALPHA
        )

        for h_key, h_label in history_map.items():
            sig_units_h = real_sig_subsets[h_key]
            n_sig = len(sig_units_h)
            stats_summary[subject][h_label] = {"n_sig": n_sig}

            if n_sig > 0:
                history_selection = [2, 3] if h_key == 2 else [h_key]

                rates_actor = get_mean_rate_for_condition(
                    dataT, sig_units_h, history_selection, 1
                )
                rates_observer = get_mean_rate_for_condition(
                    dataT, sig_units_h, history_selection, -1
                )
                real_diffs_h = np.abs(rates_actor - rates_observer)

                stats_summary[subject][h_label]["mean_diff"] = np.nanmean(
                    real_diffs_h
                )

                for diff in real_diffs_h:
                    if not np.isnan(diff):
                        all_diffs_list.append(
                            {
                                "subject": subject,
                                "history": h_key,
                                "type": "real",
                                "rate_diff": diff,
                                "shuffle_iter": 0,
                            }
                        )

        print(
            f"Running {N_SHUFFLES} shuffles for null distribution (with filtering)..."
        )
        for i_shuffle in tqdm(range(N_SHUFFLES), desc=f"Shuffling {subject}"):
            dataT_shuffled = shuffle_actor_observer(dataT)
            shuffled_sig_subsets = find_significant_rate_diff_neurons(
                dataT_shuffled, initial_sig_units, alpha=ALPHA
            )

            for h_key in history_map.keys():
                sig_units_h_shuffled = shuffled_sig_subsets[h_key]
                if len(sig_units_h_shuffled) > 0:
                    history_selection = [2, 3] if h_key == 2 else [h_key]
                    rates_actor = get_mean_rate_for_condition(
                        dataT_shuffled,
                        sig_units_h_shuffled,
                        history_selection,
                        1,
                    )
                    rates_observer = get_mean_rate_for_condition(
                        dataT_shuffled,
                        sig_units_h_shuffled,
                        history_selection,
                        -1,
                    )
                    shuffled_diffs = np.abs(rates_actor - rates_observer)

                    for diff in shuffled_diffs:
                        if not np.isnan(diff):
                            all_diffs_list.append(
                                {
                                    "subject": subject,
                                    "history": h_key,
                                    "type": "shuffled",
                                    "rate_diff": diff,
                                    "shuffle_iter": i_shuffle + 1,
                                }
                            )

    df_combined = pd.DataFrame(all_diffs_list)
    df_combined["history_label"] = df_combined["history"].map(history_map)

    plot_real_vs_shuffled_diff(root_dir, df_combined, subject="both")
    for subject in ["L", "O"]:
        df_subject = df_combined[df_combined["subject"] == subject]
        plot_real_vs_shuffled_diff(root_dir, df_subject, subject)

    output_file_path = (
        f"{root_dir}/stats_paper/actor_vs_observer_rates_stats.txt"
    )
    with open(output_file_path, "w") as file:
        file.write(
            "Permutation Test for Actor vs. Observer Rate Difference (Filtered by Rank-Sum Test)\n"
        )
        file.write(f"Significance level (alpha) for filtering: {ALPHA}\n")
        file.write("=" * 80 + "\n\n")

        df_real = df_combined[df_combined["type"] == "real"]
        df_shuffled = df_combined[df_combined["type"] == "shuffled"]

        file.write("--- Analysis for Both Subjects Combined ---\n")
        n_total_initial = sum(stats_summary[s]["initial_n"] for s in ["L", "O"])
        for h_key, h_label in history_map.items():
            n_total_sig = sum(
                stats_summary[s][h_label]["n_sig"] for s in ["L", "O"]
            )
            percent_sig = (
                (n_total_sig / n_total_initial) * 100
                if n_total_initial > 0
                else 0
            )

            real_data_h = df_real[df_real["history"] == h_key]
            real_mean_diff = (
                real_data_h["rate_diff"].mean() if not real_data_h.empty else 0
            )

            file.write(f"\nCondition: {h_label}\n")
            file.write(f"  Initial neurons considered: {n_total_initial}\n")
            file.write(
                f"  Neurons with significant difference (p<{ALPHA}): {n_total_sig} ({percent_sig:.2f}%)\n"
            )
            file.write(
                f"  Mean absolute rate difference for significant neurons: {real_mean_diff:.4f}\n"
            )

            shuffled_means_dist = (
                df_shuffled[df_shuffled["history"] == h_key]
                .groupby("shuffle_iter")["rate_diff"]
                .mean()
            )
            if not shuffled_means_dist.empty:
                p_value = (
                    np.sum(shuffled_means_dist >= real_mean_diff) + 1
                ) / (len(shuffled_means_dist) + 1)
                file.write(f"  Permutation p-value: {p_value:.4f}\n")
            else:
                file.write(
                    "  Permutation p-value: N/A (no significant units in shuffles)\n"
                )

        for subject in ["L", "O"]:
            file.write(f"\n\n--- Analysis for Subject {subject} ---\n")
            n_initial = stats_summary[subject]["initial_n"]
            for h_key, h_label in history_map.items():
                n_sig = stats_summary[subject][h_label]["n_sig"]
                percent = (n_sig / n_initial) * 100 if n_initial > 0 else 0
                mean_d = stats_summary[subject][h_label].get("mean_diff", 0)
                file.write(f"\nCondition: {h_label} (Subject {subject})\n")
                file.write(f"  Initial neurons considered: {n_initial}\n")
                file.write(
                    f"  Neurons with significant difference (p<{ALPHA}): {n_sig} ({percent:.2f}%)\n"
                )
                file.write(
                    f"  Mean absolute rate difference for significant neurons: {mean_d:.4f}\n"
                )

    print(f"\nStatistical analysis saved to {output_file_path}")


if __name__ == "__main__":
    main_actor_observer_diff()
